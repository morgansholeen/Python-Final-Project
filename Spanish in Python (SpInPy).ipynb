{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpInPy - SPanish IN PYthon\n",
    "TEAM MEMBERS: Swetha Berana, Morgan Sholeen, Lindia Tjuatja\n",
    "\n",
    "Research has shown that code switching - or the switching between languages within a single utterance - is an effective tool in language learning. We have created a program that takes user input in English and translates certain parts of the input into Spanish, as well as two alternate language modes in French and German. The result is a mixed-language sentence that allows the user to learn new Spanish/French/German vocabulary by incorporating unknown words into a known English context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules to be used\n",
    "import nltk\n",
    "from nltk.chunk import *\n",
    "from nltk.chunk.regexp import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used a number of modules and APIs to create this program. First and foremost is Python's Natural Language Toolkit (NLTK). We also used a Google translate API and an offline text to speech library from PyPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main menu\n",
    "The program has three modes which are presented to the user at the main menu. They are (1) code switch, (2) glossary, (3) change language. \n",
    "\n",
    "(1) Code switch takes user input (an English sentence) and translates and replaces the noun phrases in a different language. This will be further discussed in the code switch function. (Note: code switch function cell must be run before main menu loop)\n",
    "\n",
    "(2) Glossary presents the user with a list of all translated noun phrases. The list contains tuples of the format (original English noun phrase, translated noun phrase, language of translation).\n",
    "\n",
    "(3) Change language allows the user to change language of translation to Spanish (default), French, or German.\n",
    "\n",
    "Finally, the user can exit the program by entering the (*) character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outer loop - main menu and exit\n",
    "while(1):\n",
    "   mode = input(\"Welcome to SpInPy!\\n Main menu-- (1) code switch    (2) glossary    (3) change language    (*) exit\\n Mode select: \") \n",
    "   imode = mode\n",
    "   \n",
    "   if imode == '*':\n",
    "       print('¡Adios¡ Goodbye!')\n",
    "       break\n",
    "   \n",
    "   elif imode == '1':   #codeswitch mode\n",
    "     print('\\nCode switch mode. Enter (*) to go back to the main menu.')\n",
    "     codeswitch()\n",
    "     \n",
    "   elif imode == '2':   #view glossary\n",
    "        print('\\nGlossary\\n', gloss)\n",
    "\n",
    "   elif imode == '3':   #option to switch languages, which is then applied in codeswitch mode\n",
    "       langPrompt = 1\n",
    "       alang = ''\n",
    "       while(langPrompt):\n",
    "           lang = input(\"To return to the main menu, enter (*)\\n Enter (f) for French, (g) for German or (s) for Spanish (default): \")\n",
    "           if (lang == '*'):\n",
    "               langPrompt = 0;\n",
    "           elif (lang == 'f'):\n",
    "               alang = 'fr'\n",
    "               langPrompt = 0\n",
    "           elif (lang == 'g'):\n",
    "               alang = 'de'\n",
    "               langPrompt = 0\n",
    "           elif(lang == 's'):\n",
    "               alang = 'es'   \n",
    "               langPrompt = 0\n",
    "           else: \n",
    "               print(\"\\nNot a valid input. \")\n",
    "       destlang = alang\n",
    "       \n",
    "   else:\n",
    "       print(\"\\nNot a valid input. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main menu isn't too complicated. The largest part of this program is the code switch function called under the first elif.\n",
    "\n",
    "### codeswitch( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codeswitch funciton is composed of four parts. They are:\n",
    "1. Obtain user input (an English sentence)\n",
    "2. Parse the sentence for noun phrases via part of speech tagging and chunking*\n",
    "3. Find, translate, and replace noun phrases\n",
    "4. Print and allow user to either listen to the sentence, enter a new sentence, or return to main menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before delving into the code, here is a brief description of part of speech tagging, noun phrases, and chunking.\n",
    "\n",
    "Simply put, the NLTK part of speech tagger takes a string of tokens (such as individual words) and tags them with their part of speech (as in noun, verb, adjective, etc.). The output is a tuple of the form (word, POS tag).\n",
    "\n",
    "From there, we can group words of certain parts of speech together (i.e. \"chunking\") using regular expressions to form phrases. A noun phrase consists of an optional determiner, optionally one or more adjectives, and a noun. We specify this rule in defining NounPhrase.\n",
    "\n",
    "Why use noun phrases instead of just translating the nouns? The short answer is word alignment (although the longer one has more complicated roots in the rules code-switching syntax). For example, the word order of adjectives and nouns in English and Spanish is reversed - saying \"big dog\" in English turns into \"dog big\" in Spanish. By translating the entire noun phrase, which includes the adjective, we can avoid this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeswitch():\n",
    "    #defining what constitutes a noun phrase\n",
    "    NounPhrase = RegexpParser('''\n",
    "                              NP: {(<(DT)>)?(<(JJ)>)*(<(NN)>|<(NNS)>)} \n",
    "                              ''')\n",
    "    flag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the NounPhrase grammar rule and setting the flag parameter, we enter the while loop. The first thing is to prompt the user for an English sentence. If the input is (*), we exit back to the main menu. If the input does not end in a period, we append one for ease of parsing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    while(flag): \n",
    "        sentence = input(\"Type a sentence in English: \")\n",
    "        if sentence == '*':\n",
    "            break\n",
    "        if sentence[-1] != '.':\n",
    "            sentence = sentence + '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentence string is then tokenized (separated by word and punctuation) and then part of speech tagged. Afterwards, it is parsed by the noun phrase chunk rule we applied previously. Finally, we add beginning-inside-outside tags (which, as the name implies, marks the beginning, inside, and outside of chunks). This will aid us in finding and replacing chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        words = word_tokenize(sentence)   #tokenize string - returns list of tokens\n",
    "        tagged_words = nltk.pos_tag(words)   #tag with part of speech - returns list of tuples \n",
    "        parsed = NounPhrase.parse(tagged_words)   #parse noun phrase chunks\n",
    "        parsed_bio = nltk.chunk.tree2conlltags(parsed)   #add b-i-o tags as third element to tuples in list\n",
    "        np_chunk = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then traverse the list of tagged and chunked words. Every time a part of a noun phrase is encountered, the word is concatenated to the running np_chunk string. Once the end of a noun phrase is encountered, the string is translated, added to the glossary, and replaces the English source text. The np_chunk string is then cleared and the process repeats until the end of the list is reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for word in parsed_bio:\n",
    "            i = parsed_bio.index(word)\n",
    "            if word[2] == 'B-NP':\n",
    "                beg = parsed_bio.index(word)\n",
    "                np_chunk = np_chunk + ' ' + word[0]\n",
    "                if (parsed_bio[i+1])[2] == 'O':\n",
    "                    print(np_chunk)\n",
    "                    trans_words = (translator.translate(np_chunk, dest=destlang).text)\n",
    "                    gloss_entry = (np_chunk, trans_words, destlang)\n",
    "                    gloss.append(gloss_entry)\n",
    "                    words.insert(beg, trans_words) \n",
    "                    del parsed_bio[beg+1]\n",
    "                    del words[beg+1]\n",
    "                    np_chunk = ''\n",
    "            elif word[2] == 'I-NP':\n",
    "                np_chunk = np_chunk + ' ' + word[0]\n",
    "                if parsed_bio[parsed_bio.index(word)+1][2] == 'O':\n",
    "                    trans_words = (translator.translate(np_chunk, dest=destlang).text)\n",
    "                    gloss_entry = (np_chunk, trans_words, destlang)\n",
    "                    gloss.append(gloss_entry)\n",
    "                    words.insert(beg, trans_words) \n",
    "                    del parsed_bio[(beg+1):(i+2)]\n",
    "                    del words[(beg+1):(i+2)]\n",
    "                    np_chunk = ''\n",
    "            elif word[2] == 'O-NP':\n",
    "                np_chunk = np_chunk + ' ' + word[0]\n",
    "                trans_words = (translator.translate(np_chunk, dest=destlang).text)\n",
    "                gloss_entry = (np_chunk, trans_words, destlang)\n",
    "                gloss.append(gloss_entry)\n",
    "                words.insert(beg, trans_words) \n",
    "                del parsed_bio[(beg+1):(i+2)]\n",
    "                del words[(beg+1):(i+2)]\n",
    "                np_chunk = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the chunks have been replaced by their translations, the list is put together as a space-separated string of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if words[-1] == '.':\n",
    "            del words[-1]\n",
    "        s = ' '\n",
    "        cs_sentence = s.join(words) \n",
    "        result = cs_sentence + '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the user is prompted with the option to listen to their sentence be read out loud (disclaimer: the tts feature only supports English phonetics, so it doesn't pronounce certain foreign words correctly). Otherwise, the user can either input another sentence or return to the main menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        while(1):\n",
    "            listen = input(f'{result}\\nEnter (@) to listen, (n) to enter a new sentence, (*) to go back to main menu: ')\n",
    "            if (listen == '@'):\n",
    "                engine.say(result)\n",
    "                engine.runAndWait()\n",
    "                break\n",
    "            elif (listen == 'n'):\n",
    "                break\n",
    "            elif (listen == '*'):\n",
    "                flag = 0\n",
    "                break\n",
    "            else: \n",
    "                print(\"\\nNot a valid input. \")\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the bulk of what we have developed in SpInPy for this project. In the future, it would be interesting to add speech to text as well as language-switching for the text to speech feature. We could also train our own POS tagger to make it more accurate (sometimes the built-in NLTK tagger can be a little faulty which messes with translation).\n",
    "\n",
    "We had a fun time learning Python these past few weeks! Thanks for teaching us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sources\n",
    "- https://www.nltk.org/\n",
    "- https://pypi.org/project/googletrans/\n",
    "- https://pypi.org/project/pyttsx3/\n",
    "- https://pythonprogramming.net/chunking-nltk-tutorial/\n",
    "- https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
